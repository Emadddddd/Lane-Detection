{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ef0d37-dae5-43f2-bf41-a20b8ad2779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9245329c-a089-4a8e-ac62-b720a21a0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold=50, high_threshold=150):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size=15):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to\n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).\n",
    "\n",
    "    Think about things like separating line segments by their\n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of\n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "\n",
    "    This function draws `lines` with `color` and `thickness`.\n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "\n",
    "    Returns hough lines.\n",
    "    \"\"\"\n",
    "    return cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
    "                            maxLineGap=max_line_gap)\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = mpimg.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append((img, filename, False))\n",
    "    return images\n",
    "\n",
    "\n",
    "def show_images(images, cols, figure_size=(10, 10)):\n",
    "    rows = math.ceil(len(images)/cols)\n",
    "    fix, ax = plt.subplots(rows, cols, figsize=figure_size)\n",
    "\n",
    "    img_cnt = 0\n",
    "    img_length = len(images)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            image, title, show_gray = images[img_cnt]\n",
    "            if (rows > 1):\n",
    "                ax[i][j].set_title(title, fontsize=10)\n",
    "                if show_gray:\n",
    "                    ax[i][j].imshow(image, cmap='gray')\n",
    "                else:\n",
    "                    ax[i][j].imshow(image)\n",
    "            else:\n",
    "                ax[j].set_title(title, fontsize=10)\n",
    "                if show_gray:\n",
    "                    ax[j].imshow(image, cmap='gray')\n",
    "                else:\n",
    "                    ax[j].imshow(image)\n",
    "            img_cnt = img_cnt + 1\n",
    "            if img_cnt >= img_length:\n",
    "                break\n",
    "        if img_cnt >= img_length:\n",
    "            break\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def get_changed_images(images, modifier, image_name, show_as_gray):\n",
    "    changed_images = []\n",
    "    for image, name, _ in images:\n",
    "        changed_image = modifier(image)\n",
    "        changed_images.append((changed_image, image_name, show_as_gray))\n",
    "    return changed_images\n",
    "\n",
    "def mask_white_yellow_rgb(image):\n",
    "    # white\n",
    "    lower = np.uint8([200, 200, 200])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # yellow\n",
    "    lower = np.uint8([190, 190, 0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # combine\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "def mask_white_yellow_hls(image):\n",
    "    converted = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    # white\n",
    "    lower = np.uint8([0, 200, 0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted, lower, upper)\n",
    "    # yellow\n",
    "    lower = np.uint8([10, 0, 100])\n",
    "    upper = np.uint8([40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted, lower, upper)\n",
    "    # combine\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "def get_region_masked_images(images, imshape, row_top, bottom_col_left, top_col_left, top_col_right):\n",
    "    region_images = []\n",
    "\n",
    "    bottom_left = [bottom_col_left, imshape[0]]\n",
    "    top_left = [top_col_left, row_top]\n",
    "    bottom_right = [imshape[1], imshape[0]]\n",
    "    top_right = [top_col_right, row_top]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    for image, name, _ in images:\n",
    "        masked = region_of_interest(image, vertices)\n",
    "        name = \"region_masked\"\n",
    "        region_images.append((masked, name, True))\n",
    "    return region_images\n",
    "\n",
    "\n",
    "def get_hough_lines_all(images):\n",
    "    lines = []\n",
    "    for image, name, _ in images:\n",
    "        line = hough_lines(image, 1, np.pi/180, 20, 20, 300)\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def get_hough_lines_images(original_images, canny_images, lines_all):\n",
    "    hough_lines_images = []\n",
    "    cnt = 0\n",
    "    for image, name, _ in canny_images:\n",
    "        orig_copy = np.copy(original_images[cnt][0])\n",
    "        draw_lines(orig_copy, lines_all[0], thickness=1)\n",
    "        name = 'hough_lines'\n",
    "        hough_lines_images.append((orig_copy, name, False))\n",
    "    return hough_lines_images\n",
    "\n",
    "\n",
    "def get_lane_lines_all(images, lines_all, row_top):\n",
    "    lane_lines_all = []\n",
    "    cnt = 0\n",
    "    for image, name, _ in images:\n",
    "        lane_lines = get_lane_lines(image.shape, lines_all[cnt], row_top)\n",
    "        lane_lines_all.append(lane_lines)\n",
    "        cnt = cnt + 1\n",
    "    return lane_lines_all\n",
    "\n",
    "\n",
    "def get_images_with_lane_lines(images, lane_lines_all):\n",
    "    results = []\n",
    "    cnt = 0\n",
    "    for image, name, _ in images:\n",
    "        result = get_lane_lines_image(image, lane_lines_all[cnt])\n",
    "        results.append((result, \"result\", False))\n",
    "    return results\n",
    "\n",
    "def average_lanes(lines):\n",
    "    left_lines = []\n",
    "    left_length = []\n",
    "    right_lines = []\n",
    "    right_length = []\n",
    "\n",
    "    for line in lines:\n",
    "        for col1, row1, col2, row2 in line:\n",
    "            if col2 == col1:\n",
    "                continue  # skip if it is a vertical line\n",
    "            slope = (row2 - row1) / (col2 - col1)\n",
    "            intercept = row1 - slope * col1\n",
    "            length = np.sqrt((row2 - row1) ** 2 + (col2 - col1) ** 2)\n",
    "            if slope < 0:  # y is reversed in a matplotlib image\n",
    "                left_lines.append((slope, intercept))\n",
    "                left_length.append((length))\n",
    "            else:\n",
    "                right_lines.append((slope, intercept))\n",
    "                right_length.append((length))\n",
    "\n",
    "    left_lane = None\n",
    "    right_lane = None\n",
    "\n",
    "    # prefer longer lines\n",
    "    if len(left_length) > 0:\n",
    "        left_lane = np.dot(left_length, left_lines) / np.sum(left_length)\n",
    "\n",
    "    if len(right_length) > 0:\n",
    "        right_lane = np.dot(right_length, right_lines) / np.sum(right_length)\n",
    "\n",
    "    #(slope,intercept), (slope,intercept)\n",
    "    return left_lane, right_lane\n",
    "\n",
    "\n",
    "def get_points(row_bottom, row_top, line):\n",
    "    if line is None:\n",
    "        return None\n",
    "\n",
    "    slope, intercept = line\n",
    "\n",
    "    col_bottom = int((row_bottom - intercept) / slope)\n",
    "    col_top = int((row_top - intercept) / slope)\n",
    "\n",
    "    return ((col_bottom, int(row_bottom)), (col_top, int(row_top)))\n",
    "\n",
    "\n",
    "def get_lane_lines(imshape, lines, row_top):\n",
    "    left_lane, right_lane = average_lanes(lines)\n",
    "\n",
    "    left_line = get_points(imshape[0], row_top, left_lane)\n",
    "    right_line = get_points(imshape[0], row_top, right_lane)\n",
    "\n",
    "    return left_line, right_line\n",
    "\n",
    "\n",
    "def get_lane_lines_image(image, lines, color= [255, 0, 0], thickness=20):\n",
    "    \n",
    "    # create a new image to draw lines\n",
    "    line_image = np.zeros_like(image)\n",
    "    for line in lines:\n",
    "        if line is not None:\n",
    "            cv2.line(line_image, line[0], line[1], color, thickness)\n",
    "    return cv2.addWeighted(image, 1.0, line_image, 0.95, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96e59c4-9c54-4138-bd18-b070ec3854be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 2/221 [01:18<2:23:47, 39.39s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/221 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "t:   1%|▏         | 3/221 [00:00<00:08, 27.07it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 11/221 [00:00<00:03, 53.03it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 17/221 [00:00<00:03, 53.37it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 24/221 [00:00<00:03, 59.08it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 31/221 [00:00<00:03, 62.57it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 39/221 [00:00<00:02, 65.05it/s, now=None]\u001b[A\n",
      "t:  21%|██        | 46/221 [00:00<00:02, 66.31it/s, now=None]\u001b[A\n",
      "t:  24%|██▍       | 53/221 [00:00<00:02, 56.84it/s, now=None]\u001b[A\n",
      "t:  27%|██▋       | 59/221 [00:01<00:02, 57.53it/s, now=None]\u001b[A\n",
      "t:  29%|██▉       | 65/221 [00:01<00:02, 56.28it/s, now=None]\u001b[A\n",
      "t:  32%|███▏      | 71/221 [00:01<00:02, 55.94it/s, now=None]\u001b[A\n",
      "t:  35%|███▌      | 78/221 [00:01<00:02, 55.22it/s, now=None]\u001b[A\n",
      "t:  38%|███▊      | 85/221 [00:01<00:02, 57.33it/s, now=None]\u001b[A\n",
      "t:  42%|████▏     | 92/221 [00:01<00:02, 58.30it/s, now=None]\u001b[A\n",
      "t:  44%|████▍     | 98/221 [00:01<00:02, 57.37it/s, now=None]\u001b[A\n",
      "t:  48%|████▊     | 105/221 [00:01<00:01, 58.52it/s, now=None]\u001b[A\n",
      "t:  50%|█████     | 111/221 [00:01<00:01, 58.59it/s, now=None]\u001b[A\n",
      "t:  53%|█████▎    | 118/221 [00:02<00:01, 59.36it/s, now=None]\u001b[A\n",
      "t:  56%|█████▌    | 124/221 [00:02<00:01, 57.94it/s, now=None]\u001b[A\n",
      "t:  59%|█████▉    | 130/221 [00:02<00:01, 58.51it/s, now=None]\u001b[A\n",
      "t:  62%|██████▏   | 137/221 [00:02<00:01, 60.43it/s, now=None]\u001b[A\n",
      "t:  65%|██████▌   | 144/221 [00:02<00:01, 58.01it/s, now=None]\u001b[A\n",
      "t:  68%|██████▊   | 150/221 [00:02<00:01, 58.05it/s, now=None]\u001b[A\n",
      "t:  71%|███████   | 156/221 [00:02<00:01, 56.70it/s, now=None]\u001b[A\n",
      "t:  73%|███████▎  | 162/221 [00:02<00:01, 53.02it/s, now=None]\u001b[A\n",
      "t:  76%|███████▋  | 169/221 [00:02<00:00, 56.84it/s, now=None]\u001b[A\n",
      "t:  79%|███████▉  | 175/221 [00:03<00:00, 57.56it/s, now=None]\u001b[A\n",
      "t:  82%|████████▏ | 181/221 [00:03<00:00, 56.82it/s, now=None]\u001b[A\n",
      "t:  85%|████████▍ | 187/221 [00:03<00:00, 56.27it/s, now=None]\u001b[A\n",
      "t:  87%|████████▋ | 193/221 [00:03<00:00, 55.97it/s, now=None]\u001b[A\n",
      "t:  90%|█████████ | 199/221 [00:03<00:00, 53.57it/s, now=None]\u001b[A\n",
      "t:  93%|█████████▎| 205/221 [00:03<00:00, 52.92it/s, now=None]\u001b[A\n",
      "t:  95%|█████████▌| 211/221 [00:03<00:00, 53.07it/s, now=None]\u001b[A\n",
      "t:  98%|█████████▊| 217/221 [00:03<00:00, 52.56it/s, now=None]\u001b[A\n",
      "t:   1%|          | 2/221 [01:23<2:31:43, 41.57s/it, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidWhiteRight.mp4\n",
      "CPU times: total: 6.47 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "QUEUE_MAX_LEN = 50\n",
    "\n",
    "left_lines  = collections.deque(maxlen=QUEUE_MAX_LEN)\n",
    "right_lines = collections.deque(maxlen=QUEUE_MAX_LEN)\n",
    "\n",
    "def get_average_line(line, lines):\n",
    "    if line is not None:\n",
    "        lines.append(line)\n",
    "\n",
    "    if len(lines)>0:\n",
    "        line = np.mean(lines, axis=0, dtype=np.int32)\n",
    "        line = tuple(map(tuple, line))\n",
    "    return line\n",
    "        \n",
    "def process_image(image):\n",
    "    # test videos 1, 2\n",
    "    row_top = 330\n",
    "    bottom_col_left = 100\n",
    "    top_col_left = 450\n",
    "    top_col_right = 560\n",
    "    \n",
    "    # challenge video\n",
    "    #row_top = 430\n",
    "    #bottom_col_left = 100\n",
    "    #top_col_left = 500\n",
    "    #top_col_right = 800\n",
    "\n",
    "    bottom_left = [bottom_col_left, image.shape[0]]\n",
    "    top_left = [top_col_left, row_top]\n",
    "    bottom_right = [image.shape[1], image.shape[0]]\n",
    "    top_right = [top_col_right, row_top]\n",
    "\n",
    "    hls_masked_image = mask_white_yellow_hls(image)\n",
    "    gray = grayscale(hls_masked_image)\n",
    "    blur_gray = gaussian_blur(gray, 15)\n",
    "    edges = canny(blur_gray, 50, 150)\n",
    "\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 1  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 5  # minimum number of pixels making up a line\n",
    "    max_line_gap = 1  # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    h_lines = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    lane_lines = get_lane_lines(image.shape, h_lines, row_top)\n",
    "\n",
    "    left_line = get_average_line(lane_lines[0], left_lines)\n",
    "    right_line = get_average_line(lane_lines[1], right_lines)\n",
    "    result = get_lane_lines_image(image, (left_line, right_line))\n",
    "    return result\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b513db8e-ce9c-4809-af32-f26217dd0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb70086-da1a-4561-8827-47516617c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 2/221 [02:28<4:30:24, 74.08s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidYellowLeft.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidYellowLeft.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/681 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "t:   0%|          | 3/681 [00:00<00:25, 26.37it/s, now=None]\u001b[A\n",
      "t:   1%|▏         | 9/681 [00:00<00:15, 43.01it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 15/681 [00:00<00:13, 48.91it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 22/681 [00:00<00:11, 55.23it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 28/681 [00:00<00:11, 56.51it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 34/681 [00:00<00:11, 55.43it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 40/681 [00:00<00:12, 51.58it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 46/681 [00:00<00:13, 48.56it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 51/681 [00:01<00:13, 45.16it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 56/681 [00:01<00:13, 46.33it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 61/681 [00:01<00:13, 47.20it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 67/681 [00:01<00:12, 48.78it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 72/681 [00:01<00:12, 47.70it/s, now=None]\u001b[A\n",
      "t:  11%|█▏        | 78/681 [00:01<00:12, 49.09it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 84/681 [00:01<00:11, 50.82it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 90/681 [00:01<00:11, 51.38it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 96/681 [00:01<00:11, 50.99it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 102/681 [00:02<00:11, 48.59it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 107/681 [00:02<00:13, 42.13it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 113/681 [00:02<00:12, 44.90it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 119/681 [00:02<00:11, 47.40it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 124/681 [00:02<00:12, 45.52it/s, now=None]\u001b[A\n",
      "t:  19%|█▉        | 129/681 [00:02<00:12, 45.38it/s, now=None]\u001b[A\n",
      "t:  20%|█▉        | 135/681 [00:02<00:11, 47.15it/s, now=None]\u001b[A\n",
      "t:  21%|██        | 141/681 [00:02<00:11, 48.30it/s, now=None]\u001b[A\n",
      "t:  21%|██▏       | 146/681 [00:03<00:11, 48.42it/s, now=None]\u001b[A\n",
      "t:  22%|██▏       | 152/681 [00:03<00:10, 51.44it/s, now=None]\u001b[A\n",
      "t:  23%|██▎       | 158/681 [00:03<00:09, 52.71it/s, now=None]\u001b[A\n",
      "t:  24%|██▍       | 164/681 [00:03<00:09, 53.33it/s, now=None]\u001b[A\n",
      "t:  25%|██▍       | 170/681 [00:03<00:11, 45.79it/s, now=None]\u001b[A\n",
      "t:  26%|██▌       | 175/681 [00:03<00:12, 41.51it/s, now=None]\u001b[A\n",
      "t:  27%|██▋       | 181/681 [00:03<00:10, 45.77it/s, now=None]\u001b[A\n",
      "t:  27%|██▋       | 186/681 [00:03<00:10, 46.82it/s, now=None]\u001b[A\n",
      "t:  28%|██▊       | 191/681 [00:04<00:11, 44.23it/s, now=None]\u001b[A\n",
      "t:  29%|██▉       | 197/681 [00:04<00:10, 48.30it/s, now=None]\u001b[A\n",
      "t:  30%|██▉       | 203/681 [00:04<00:09, 48.58it/s, now=None]\u001b[A\n",
      "t:  31%|███       | 208/681 [00:04<00:10, 45.22it/s, now=None]\u001b[A\n",
      "t:  32%|███▏      | 215/681 [00:04<00:09, 49.63it/s, now=None]\u001b[A\n",
      "t:  32%|███▏      | 221/681 [00:04<00:09, 47.67it/s, now=None]\u001b[A\n",
      "t:  33%|███▎      | 226/681 [00:04<00:09, 47.20it/s, now=None]\u001b[A\n",
      "t:  34%|███▍      | 232/681 [00:04<00:09, 49.59it/s, now=None]\u001b[A\n",
      "t:  35%|███▍      | 238/681 [00:04<00:09, 47.95it/s, now=None]\u001b[A\n",
      "t:  36%|███▌      | 244/681 [00:05<00:08, 49.55it/s, now=None]\u001b[A\n",
      "t:  37%|███▋      | 250/681 [00:05<00:09, 47.60it/s, now=None]\u001b[A\n",
      "t:  37%|███▋      | 255/681 [00:05<00:09, 46.08it/s, now=None]\u001b[A\n",
      "t:  38%|███▊      | 262/681 [00:05<00:08, 51.33it/s, now=None]\u001b[A\n",
      "t:  40%|███▉      | 269/681 [00:05<00:07, 56.27it/s, now=None]\u001b[A\n",
      "t:  40%|████      | 275/681 [00:05<00:07, 53.73it/s, now=None]\u001b[A\n",
      "t:  41%|████▏     | 281/681 [00:05<00:08, 48.62it/s, now=None]\u001b[A\n",
      "t:  42%|████▏     | 288/681 [00:05<00:07, 52.89it/s, now=None]\u001b[A\n",
      "t:  43%|████▎     | 295/681 [00:06<00:07, 54.51it/s, now=None]\u001b[A\n",
      "t:  44%|████▍     | 302/681 [00:06<00:06, 56.60it/s, now=None]\u001b[A\n",
      "t:  45%|████▌     | 309/681 [00:06<00:06, 59.53it/s, now=None]\u001b[A\n",
      "t:  46%|████▋     | 316/681 [00:06<00:06, 60.41it/s, now=None]\u001b[A\n",
      "t:  47%|████▋     | 323/681 [00:06<00:05, 62.08it/s, now=None]\u001b[A\n",
      "t:  48%|████▊     | 330/681 [00:06<00:05, 61.12it/s, now=None]\u001b[A\n",
      "t:  49%|████▉     | 337/681 [00:06<00:05, 60.77it/s, now=None]\u001b[A\n",
      "t:  51%|█████     | 344/681 [00:06<00:05, 58.86it/s, now=None]\u001b[A\n",
      "t:  52%|█████▏    | 351/681 [00:06<00:05, 59.55it/s, now=None]\u001b[A\n",
      "t:  53%|█████▎    | 358/681 [00:07<00:05, 60.01it/s, now=None]\u001b[A\n",
      "t:  54%|█████▎    | 365/681 [00:07<00:05, 61.29it/s, now=None]\u001b[A\n",
      "t:  55%|█████▍    | 372/681 [00:07<00:05, 61.22it/s, now=None]\u001b[A\n",
      "t:  56%|█████▌    | 379/681 [00:07<00:04, 61.60it/s, now=None]\u001b[A\n",
      "t:  57%|█████▋    | 386/681 [00:07<00:04, 61.76it/s, now=None]\u001b[A\n",
      "t:  58%|█████▊    | 393/681 [00:07<00:04, 61.71it/s, now=None]\u001b[A\n",
      "t:  59%|█████▊    | 400/681 [00:07<00:04, 57.08it/s, now=None]\u001b[A\n",
      "t:  60%|█████▉    | 406/681 [00:07<00:04, 55.20it/s, now=None]\u001b[A\n",
      "t:  60%|██████    | 412/681 [00:08<00:05, 53.19it/s, now=None]\u001b[A\n",
      "t:  61%|██████▏   | 418/681 [00:08<00:05, 48.79it/s, now=None]\u001b[A\n",
      "t:  62%|██████▏   | 424/681 [00:08<00:05, 49.86it/s, now=None]\u001b[A\n",
      "t:  63%|██████▎   | 430/681 [00:08<00:04, 50.26it/s, now=None]\u001b[A\n",
      "t:  64%|██████▍   | 437/681 [00:08<00:04, 53.50it/s, now=None]\u001b[A\n",
      "t:  65%|██████▌   | 443/681 [00:08<00:04, 52.74it/s, now=None]\u001b[A\n",
      "t:  66%|██████▌   | 449/681 [00:08<00:04, 53.52it/s, now=None]\u001b[A\n",
      "t:  67%|██████▋   | 455/681 [00:08<00:04, 54.02it/s, now=None]\u001b[A\n",
      "t:  68%|██████▊   | 461/681 [00:08<00:04, 53.04it/s, now=None]\u001b[A\n",
      "t:  69%|██████▊   | 467/681 [00:09<00:03, 54.04it/s, now=None]\u001b[A\n",
      "t:  69%|██████▉   | 473/681 [00:09<00:03, 53.52it/s, now=None]\u001b[A\n",
      "t:  70%|███████   | 479/681 [00:09<00:03, 53.93it/s, now=None]\u001b[A\n",
      "t:  71%|███████   | 485/681 [00:09<00:03, 54.20it/s, now=None]\u001b[A\n",
      "t:  72%|███████▏  | 492/681 [00:09<00:03, 56.09it/s, now=None]\u001b[A\n",
      "t:  73%|███████▎  | 498/681 [00:09<00:03, 55.52it/s, now=None]\u001b[A\n",
      "t:  74%|███████▍  | 504/681 [00:09<00:03, 55.83it/s, now=None]\u001b[A\n",
      "t:  75%|███████▍  | 510/681 [00:09<00:03, 55.88it/s, now=None]\u001b[A\n",
      "t:  76%|███████▌  | 516/681 [00:09<00:02, 56.89it/s, now=None]\u001b[A\n",
      "t:  77%|███████▋  | 522/681 [00:10<00:02, 56.47it/s, now=None]\u001b[A\n",
      "t:  78%|███████▊  | 528/681 [00:10<00:02, 57.20it/s, now=None]\u001b[A\n",
      "t:  79%|███████▊  | 535/681 [00:10<00:02, 58.47it/s, now=None]\u001b[A\n",
      "t:  79%|███████▉  | 541/681 [00:10<00:02, 57.44it/s, now=None]\u001b[A\n",
      "t:  80%|████████  | 547/681 [00:10<00:02, 56.77it/s, now=None]\u001b[A\n",
      "t:  81%|████████  | 553/681 [00:10<00:02, 57.66it/s, now=None]\u001b[A\n",
      "t:  82%|████████▏ | 559/681 [00:10<00:02, 54.48it/s, now=None]\u001b[A\n",
      "t:  83%|████████▎ | 566/681 [00:10<00:02, 56.37it/s, now=None]\u001b[A\n",
      "t:  84%|████████▍ | 572/681 [00:10<00:01, 56.53it/s, now=None]\u001b[A\n",
      "t:  85%|████████▍ | 578/681 [00:11<00:01, 54.20it/s, now=None]\u001b[A\n",
      "t:  86%|████████▌ | 584/681 [00:11<00:01, 55.75it/s, now=None]\u001b[A\n",
      "t:  87%|████████▋ | 590/681 [00:11<00:01, 56.91it/s, now=None]\u001b[A\n",
      "t:  88%|████████▊ | 596/681 [00:11<00:01, 55.32it/s, now=None]\u001b[A\n",
      "t:  89%|████████▊ | 603/681 [00:11<00:01, 56.52it/s, now=None]\u001b[A\n",
      "t:  89%|████████▉ | 609/681 [00:11<00:01, 55.16it/s, now=None]\u001b[A\n",
      "t:  90%|█████████ | 616/681 [00:11<00:01, 56.86it/s, now=None]\u001b[A\n",
      "t:  91%|█████████▏| 622/681 [00:11<00:01, 55.63it/s, now=None]\u001b[A\n",
      "t:  92%|█████████▏| 628/681 [00:11<00:00, 54.73it/s, now=None]\u001b[A\n",
      "t:  93%|█████████▎| 634/681 [00:12<00:00, 54.97it/s, now=None]\u001b[A\n",
      "t:  94%|█████████▍| 640/681 [00:12<00:00, 55.13it/s, now=None]\u001b[A\n",
      "t:  95%|█████████▍| 646/681 [00:12<00:00, 56.47it/s, now=None]\u001b[A\n",
      "t:  96%|█████████▌| 652/681 [00:12<00:00, 56.35it/s, now=None]\u001b[A\n",
      "t:  97%|█████████▋| 658/681 [00:12<00:00, 57.37it/s, now=None]\u001b[A\n",
      "t:  98%|█████████▊| 664/681 [00:12<00:00, 56.87it/s, now=None]\u001b[A\n",
      "t:  99%|█████████▊| 671/681 [00:12<00:00, 60.20it/s, now=None]\u001b[A\n",
      "t: 100%|█████████▉| 678/681 [00:12<00:00, 55.54it/s, now=None]\u001b[A\n",
      "t:   1%|          | 2/221 [02:41<4:54:40, 80.73s/it, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidYellowLeft.mp4\n",
      "CPU times: total: 21.5 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4b01d4-c862-42bd-b1dd-c17baa63fa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da914ef5-0db6-481b-9206-44864178cdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
